{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38tf2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c280211521d66f37a52b0842d7cb3bda35983abef4a998be7afa35eb41438e1e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import section\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "from keras.models import  Model, Sequential\n",
    "from keras.layers import Dense, Input, LSTM ,Embedding , TimeDistributed, BatchNormalization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "source": [
    "## HDFS Time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_log = './data/HDFS_100k.log_structured.csv' # The structured log file\n",
    "label_file = './data/HDFS_100k.log_anomaly_label.csv' # The anomaly label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   LineId   Date    Time  Pid Level                     Component  \\\n",
       "0       1  81109  203518  143  INFO      dfs.DataNode$DataXceiver   \n",
       "1       2  81109  203518   35  INFO              dfs.FSNamesystem   \n",
       "2       3  81109  203519  143  INFO      dfs.DataNode$DataXceiver   \n",
       "3       4  81109  203519  145  INFO      dfs.DataNode$DataXceiver   \n",
       "4       5  81109  203519  145  INFO  dfs.DataNode$PacketResponder   \n",
       "\n",
       "                                             Content EventId  \\\n",
       "0  Receiving block blk_-1608999687919862906 src: ...      E5   \n",
       "1  BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...     E22   \n",
       "2  Receiving block blk_-1608999687919862906 src: ...      E5   \n",
       "3  Receiving block blk_-1608999687919862906 src: ...      E5   \n",
       "4  PacketResponder 1 for block blk_-1608999687919...     E11   \n",
       "\n",
       "                                   EventTemplate  \n",
       "0       Receiving block <*> src: /<*> dest: /<*>  \n",
       "1            BLOCK* NameSystem.allocateBlock:<*>  \n",
       "2       Receiving block <*> src: /<*> dest: /<*>  \n",
       "3       Receiving block <*> src: /<*> dest: /<*>  \n",
       "4  PacketResponder <*> for block <*> terminating  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LineId</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Pid</th>\n      <th>Level</th>\n      <th>Component</th>\n      <th>Content</th>\n      <th>EventId</th>\n      <th>EventTemplate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>81109</td>\n      <td>203518</td>\n      <td>143</td>\n      <td>INFO</td>\n      <td>dfs.DataNode$DataXceiver</td>\n      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n      <td>E5</td>\n      <td>Receiving block &lt;*&gt; src: /&lt;*&gt; dest: /&lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>81109</td>\n      <td>203518</td>\n      <td>35</td>\n      <td>INFO</td>\n      <td>dfs.FSNamesystem</td>\n      <td>BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...</td>\n      <td>E22</td>\n      <td>BLOCK* NameSystem.allocateBlock:&lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>81109</td>\n      <td>203519</td>\n      <td>143</td>\n      <td>INFO</td>\n      <td>dfs.DataNode$DataXceiver</td>\n      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n      <td>E5</td>\n      <td>Receiving block &lt;*&gt; src: /&lt;*&gt; dest: /&lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>81109</td>\n      <td>203519</td>\n      <td>145</td>\n      <td>INFO</td>\n      <td>dfs.DataNode$DataXceiver</td>\n      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n      <td>E5</td>\n      <td>Receiving block &lt;*&gt; src: /&lt;*&gt; dest: /&lt;*&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>81109</td>\n      <td>203519</td>\n      <td>145</td>\n      <td>INFO</td>\n      <td>dfs.DataNode$PacketResponder</td>\n      <td>PacketResponder 1 for block blk_-1608999687919...</td>\n      <td>E11</td>\n      <td>PacketResponder &lt;*&gt; for block &lt;*&gt; terminating</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "df = pd.read_csv(struct_log)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====== Input data summary ======\n",
      "Loading ./data/HDFS_100k.log_structured.csv\n",
      "Slicing 1406 sessions, with window 10\n",
      "Slicing done, 96459 windows generated\n",
      "Train: windows\n"
     ]
    }
   ],
   "source": [
    "from utils import dataloader\n",
    "from utils.preprocessing import Vectorizer_sys\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "hidden_size = 32\n",
    "num_directions = 2\n",
    "topk = 5\n",
    "train_ratio = 0.2\n",
    "window_size = 10\n",
    "epoches = 2\n",
    "num_workers = 2\n",
    "device = 0 \n",
    "\n",
    "x_, window_y_ = \\\n",
    "dataloader.load_HDFS(struct_log, window='session',window_size=window_size, train_ratio=train_ratio, split_type='uniform', Time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Vectorizer_sys()\n",
    "train_dataset = feature_extractor.fit_transform(x_, window_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4, 9, 1, ..., 1, 1, 1],\n",
       "       [4, 4, 5, ..., 6, 3, 3],\n",
       "       [4, 5, 5, ..., 3, 3, 3],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 1, 1, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1]])"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "train_dataset['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['x'] = train_dataset['x']/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.23529412, 0.52941176, 0.05882353, ..., 0.05882353, 0.05882353,\n",
       "        0.05882353],\n",
       "       [0.23529412, 0.23529412, 0.29411765, ..., 0.35294118, 0.17647059,\n",
       "        0.17647059],\n",
       "       [0.23529412, 0.29411765, 0.29411765, ..., 0.17647059, 0.17647059,\n",
       "        0.17647059],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.05882353, ..., 0.05882353, 0.05882353,\n",
       "        0.05882353],\n",
       "       [0.        , 0.05882353, 0.05882353, ..., 0.05882353, 0.05882353,\n",
       "        0.05882353],\n",
       "       [0.        , 0.        , 0.        , ..., 0.05882353, 0.05882353,\n",
       "        0.05882353]])"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "train_dataset['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "754/754 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.0678\n",
      "Epoch 2/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0112 - accuracy: 0.0617\n",
      "Epoch 3/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0081 - accuracy: 0.1005\n",
      "Epoch 4/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1273\n",
      "Epoch 5/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1472\n",
      "Epoch 6/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1530\n",
      "Epoch 7/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1538\n",
      "Epoch 8/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1698\n",
      "Epoch 9/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1471\n",
      "Epoch 10/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1533\n",
      "Epoch 11/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1540\n",
      "Epoch 12/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1459\n",
      "Epoch 13/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1569\n",
      "Epoch 14/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1563\n",
      "Epoch 15/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1558\n",
      "Epoch 16/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1469\n",
      "Epoch 17/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1352\n",
      "Epoch 18/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1525\n",
      "Epoch 19/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1367\n",
      "Epoch 20/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1379\n",
      "Epoch 21/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1530\n",
      "Epoch 22/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1390\n",
      "Epoch 23/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1629\n",
      "Epoch 24/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1403\n",
      "Epoch 25/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1605\n",
      "Epoch 26/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1439\n",
      "Epoch 27/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1545\n",
      "Epoch 28/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1391\n",
      "Epoch 29/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1448\n",
      "Epoch 30/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1528\n",
      "Epoch 31/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1424\n",
      "Epoch 32/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1292\n",
      "Epoch 33/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1423\n",
      "Epoch 34/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1321\n",
      "Epoch 35/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1534\n",
      "Epoch 36/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1452\n",
      "Epoch 37/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1331\n",
      "Epoch 38/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1372\n",
      "Epoch 39/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1566\n",
      "Epoch 40/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1366\n",
      "Epoch 41/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1465\n",
      "Epoch 42/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1258\n",
      "Epoch 43/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1533\n",
      "Epoch 44/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1439\n",
      "Epoch 45/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1315\n",
      "Epoch 46/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1512\n",
      "Epoch 47/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1355\n",
      "Epoch 48/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1478\n",
      "Epoch 49/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1437\n",
      "Epoch 50/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1497\n",
      "Epoch 51/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.1331\n",
      "Epoch 52/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1503\n",
      "Epoch 53/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1511\n",
      "Epoch 54/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1398\n",
      "Epoch 55/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1517\n",
      "Epoch 56/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1461\n",
      "Epoch 57/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1364\n",
      "Epoch 58/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1395\n",
      "Epoch 59/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1456\n",
      "Epoch 60/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1433\n",
      "Epoch 61/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1267\n",
      "Epoch 62/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1503\n",
      "Epoch 63/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1468\n",
      "Epoch 64/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1470\n",
      "Epoch 65/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1310\n",
      "Epoch 66/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1503\n",
      "Epoch 67/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1549\n",
      "Epoch 68/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1392\n",
      "Epoch 69/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1585\n",
      "Epoch 70/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1633\n",
      "Epoch 71/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1574\n",
      "Epoch 72/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1519\n",
      "Epoch 73/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1598\n",
      "Epoch 74/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1419\n",
      "Epoch 75/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1582\n",
      "Epoch 76/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.1597\n",
      "Epoch 77/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1431\n",
      "Epoch 78/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1458\n",
      "Epoch 79/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1646\n",
      "Epoch 80/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1491\n",
      "Epoch 81/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1529\n",
      "Epoch 82/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1629\n",
      "Epoch 83/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1652\n",
      "Epoch 84/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1598\n",
      "Epoch 85/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1573\n",
      "Epoch 86/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1510\n",
      "Epoch 87/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1654\n",
      "Epoch 88/100\n",
      "754/754 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.1547\n",
      "Epoch 89/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1587\n",
      "Epoch 90/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1556\n",
      "Epoch 91/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1653\n",
      "Epoch 92/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1511\n",
      "Epoch 93/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1621\n",
      "Epoch 94/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1502\n",
      "Epoch 95/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1702\n",
      "Epoch 96/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1620\n",
      "Epoch 97/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1634\n",
      "Epoch 98/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1620\n",
      "Epoch 99/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0074 - accuracy: 0.1669\n",
      "Epoch 100/100\n",
      "754/754 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.1664\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder model.\n",
    "input_dim = train_dataset['x'].shape[1]\n",
    "input = Input(shape=(input_dim, ))\n",
    "encode = Dense(input_dim//3*2, activation='relu',kernel_regularizer=regularizers.l2(0.01))(input)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(input_dim//3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(1, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "encode = BatchNormalization()(encode)\n",
    "\n",
    "decode = Dense(input_dim//3, activation='relu')(encode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim//3*2, activation='relu')(decode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim, activation='sigmoid')(decode)\n",
    "\n",
    "autoencoder = Model(input, decode)\n",
    "\n",
    "autoencoder.compile(optimizer='adam',\n",
    "            loss='mse',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Train model.\n",
    "history = autoencoder.fit(train_dataset['x'], train_dataset['x'],\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        shuffle=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['x_1auto'] = autoencoder.predict(train_dataset['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.00784969178497342"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "mean_squared_error(train_x, autoencoder.predict(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(random_state = 42, contamination = 0.3)\n",
    "clf.fit(train_dataset['x_1auto'])\n",
    "pred = clf.predict(train_dataset['x_1auto'])\n",
    "\n",
    "p1 = train_dataset['x_1auto'][pred==1]\n",
    "p2 = train_dataset['x_1auto'][pred==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normal data count : 67548\nAbnormal data count : 28911\n"
     ]
    }
   ],
   "source": [
    "print('Normal data count : {}'.format(len(p1)))\n",
    "print('Abnormal data count : {}'.format(len(p2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "528/528 [==============================] - 2s 2ms/step - loss: 0.7947 - accuracy: 0.0950\n",
      "Epoch 2/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.6224 - accuracy: 0.0972\n",
      "Epoch 3/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.3678\n",
      "Epoch 4/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5850 - accuracy: 0.4214\n",
      "Epoch 5/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5815 - accuracy: 0.7198\n",
      "Epoch 6/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5811 - accuracy: 0.8969\n",
      "Epoch 7/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9311\n",
      "Epoch 9/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9353\n",
      "Epoch 10/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9390\n",
      "Epoch 11/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9451\n",
      "Epoch 12/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9403\n",
      "Epoch 13/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9360\n",
      "Epoch 14/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9469\n",
      "Epoch 15/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9509\n",
      "Epoch 16/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9482\n",
      "Epoch 17/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9506\n",
      "Epoch 18/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9485\n",
      "Epoch 19/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9469\n",
      "Epoch 20/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9306\n",
      "Epoch 21/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9470\n",
      "Epoch 22/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9510\n",
      "Epoch 23/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9474\n",
      "Epoch 24/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9518\n",
      "Epoch 25/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9480\n",
      "Epoch 26/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9545\n",
      "Epoch 27/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9510\n",
      "Epoch 28/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9492\n",
      "Epoch 29/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9452\n",
      "Epoch 30/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9486\n",
      "Epoch 31/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9528\n",
      "Epoch 32/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9506\n",
      "Epoch 33/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9516\n",
      "Epoch 34/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9402\n",
      "Epoch 35/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9449\n",
      "Epoch 36/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9511\n",
      "Epoch 37/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.9454\n",
      "Epoch 38/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9519\n",
      "Epoch 39/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5817 - accuracy: 0.5460\n",
      "Epoch 40/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.5882\n",
      "Epoch 41/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.7462\n",
      "Epoch 42/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9200\n",
      "Epoch 43/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9435\n",
      "Epoch 44/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9502\n",
      "Epoch 45/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5809 - accuracy: 0.9570\n",
      "Epoch 46/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9552\n",
      "Epoch 47/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9559\n",
      "Epoch 48/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5806 - accuracy: 0.9556\n",
      "Epoch 49/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9529\n",
      "Epoch 50/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9564\n",
      "Epoch 51/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9533\n",
      "Epoch 52/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9549\n",
      "Epoch 53/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.9565\n",
      "Epoch 54/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9600\n",
      "Epoch 55/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9373\n",
      "Epoch 56/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9108\n",
      "Epoch 57/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9559\n",
      "Epoch 58/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.9545\n",
      "Epoch 59/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9542\n",
      "Epoch 60/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9539\n",
      "Epoch 61/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.9555\n",
      "Epoch 62/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9522\n",
      "Epoch 63/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.9521\n",
      "Epoch 64/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5809 - accuracy: 0.9526\n",
      "Epoch 65/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9522\n",
      "Epoch 66/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9539\n",
      "Epoch 67/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.9503\n",
      "Epoch 68/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9495\n",
      "Epoch 69/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9529\n",
      "Epoch 70/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9496\n",
      "Epoch 71/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9511\n",
      "Epoch 72/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9494\n",
      "Epoch 73/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9490\n",
      "Epoch 74/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9567\n",
      "Epoch 75/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9526\n",
      "Epoch 76/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9447\n",
      "Epoch 77/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.9539\n",
      "Epoch 78/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9535\n",
      "Epoch 79/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5806 - accuracy: 0.9511\n",
      "Epoch 80/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5806 - accuracy: 0.9553\n",
      "Epoch 81/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5810 - accuracy: 0.9529\n",
      "Epoch 82/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.9562\n",
      "Epoch 83/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9528\n",
      "Epoch 84/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.9503\n",
      "Epoch 85/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.9436\n",
      "Epoch 86/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.9601\n",
      "Epoch 87/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9523\n",
      "Epoch 88/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9416\n",
      "Epoch 89/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9567\n",
      "Epoch 90/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9525\n",
      "Epoch 91/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.9553\n",
      "Epoch 92/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9483\n",
      "Epoch 93/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9453\n",
      "Epoch 94/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5808 - accuracy: 0.9440\n",
      "Epoch 95/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5809 - accuracy: 0.9613\n",
      "Epoch 96/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.9530\n",
      "Epoch 97/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.9522\n",
      "Epoch 98/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5809 - accuracy: 0.9588\n",
      "Epoch 99/100\n",
      "528/528 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.9537\n",
      "Epoch 100/100\n",
      "528/528 [==============================] - 1s 1ms/step - loss: 0.5808 - accuracy: 0.9435\n"
     ]
    }
   ],
   "source": [
    "# NN Autoencoder model.\n",
    "input_dim = p1.shape[1]\n",
    "input = Input(shape=(input_dim, ))\n",
    "encode = Dense(input_dim//3*2, activation='relu',kernel_regularizer=regularizers.l2(0.01))(input)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(input_dim//3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(1, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "encode = BatchNormalization()(encode)\n",
    "\n",
    "decode = Dense(input_dim//3, activation='relu')(encode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim//3*2, activation='relu')(decode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim, activation='sigmoid')(decode)\n",
    "\n",
    "autoencoder = Model(input, decode)\n",
    "\n",
    "autoencoder.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Train model.\n",
    "history = autoencoder.fit(p1, p1,\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        shuffle=True\n",
    "        )"
   ]
  },
  {
   "source": [
    "## syslog"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_log = './data/ha2.txt_structured.csv' # The structured log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(struct_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   LineId        date      time               ip  \\\n",
       "0       1  2021-01-19  10:30:48    172.30.171.22   \n",
       "1       2  2021-01-19  10:30:48    172.30.171.22   \n",
       "2       3  2021-01-19  10:30:04  121.135.187.201   \n",
       "3       4  2021-01-19  10:30:04  121.135.187.201   \n",
       "4       5  2021-01-19  10:30:04  121.135.187.201   \n",
       "\n",
       "                                             Content   EventId  \\\n",
       "0  BENIT_Client IP1 : 114.119.158.142, user_no : ...  73aa200a   \n",
       "1  BENIT_Client IP2 : 114.119.158.142, user_no : ...  41de2f67   \n",
       "2  BENIT_Client IP2 : 203.225.82.146, user_no : n...  c06227d3   \n",
       "3  BENIT_Client IP2 : 203.225.82.146, user_no : n...  6d35b111   \n",
       "4  BENIT_Client IP1 : 203.225.82.146, user_no : n...  73aa200a   \n",
       "\n",
       "                                       EventTemplate  \n",
       "0  BENIT_Client <*> : <*>, user_no :  session_id ...  \n",
       "1  BENIT_Client <*> : <*>, user_no : null, Header...  \n",
       "2  BENIT_Client <*> : <*>, user_no : null, Header...  \n",
       "3  BENIT_Client <*> : <*>, user_no : null, Header...  \n",
       "4  BENIT_Client <*> : <*>, user_no :  session_id ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LineId</th>\n      <th>date</th>\n      <th>time</th>\n      <th>ip</th>\n      <th>Content</th>\n      <th>EventId</th>\n      <th>EventTemplate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2021-01-19</td>\n      <td>10:30:48</td>\n      <td>172.30.171.22</td>\n      <td>BENIT_Client IP1 : 114.119.158.142, user_no : ...</td>\n      <td>73aa200a</td>\n      <td>BENIT_Client &lt;*&gt; : &lt;*&gt;, user_no :  session_id ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2021-01-19</td>\n      <td>10:30:48</td>\n      <td>172.30.171.22</td>\n      <td>BENIT_Client IP2 : 114.119.158.142, user_no : ...</td>\n      <td>41de2f67</td>\n      <td>BENIT_Client &lt;*&gt; : &lt;*&gt;, user_no : null, Header...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2021-01-19</td>\n      <td>10:30:04</td>\n      <td>121.135.187.201</td>\n      <td>BENIT_Client IP2 : 203.225.82.146, user_no : n...</td>\n      <td>c06227d3</td>\n      <td>BENIT_Client &lt;*&gt; : &lt;*&gt;, user_no : null, Header...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2021-01-19</td>\n      <td>10:30:04</td>\n      <td>121.135.187.201</td>\n      <td>BENIT_Client IP2 : 203.225.82.146, user_no : n...</td>\n      <td>6d35b111</td>\n      <td>BENIT_Client &lt;*&gt; : &lt;*&gt;, user_no : null, Header...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2021-01-19</td>\n      <td>10:30:04</td>\n      <td>121.135.187.201</td>\n      <td>BENIT_Client IP1 : 203.225.82.146, user_no : n...</td>\n      <td>73aa200a</td>\n      <td>BENIT_Client &lt;*&gt; : &lt;*&gt;, user_no :  session_id ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====== Input data summary ======\n",
      "Loading ./data/ha2.txt_structured.csv\n",
      "Slicing 769 sessions, with window 10\n",
      "Slicing done, 4191 windows generated\n",
      "Train: windows\n"
     ]
    }
   ],
   "source": [
    "from utils import dataloader\n",
    "from utils.preprocessing import Vectorizer_sys\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "hidden_size = 32\n",
    "num_directions = 2\n",
    "topk = 5\n",
    "train_ratio = 0.2\n",
    "window_size = 10\n",
    "epoches = 2\n",
    "num_workers = 2\n",
    "device = 0 \n",
    "\n",
    "x_, window_y_ = \\\n",
    "dataloader.load_sys(struct_log, window='session', window_size=window_size, train_ratio=train_ratio, split_type='uniform',Time =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Vectorizer_sys()\n",
    "train_dataset = feature_extractor.fit_transform(x_, window_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['x'] = train_dataset['x'] /266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 3)                 6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 10)                70        \n",
      "=================================================================\n",
      "Total params: 267\n",
      "Trainable params: 229\n",
      "Non-trainable params: 38\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.1463\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.1380\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.1339\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.1435\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1570\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.1449\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.1523\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.1397\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.1440\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1012 - accuracy: 0.1355\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0865 - accuracy: 0.1269\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.1188\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.1126\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.1119\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.1111\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.1110\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.1105\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.1121\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.1014\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.1164\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.1178\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.1006\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.1120\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.1140\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.1467\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.1627\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0318 - accuracy: 0.1673\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.1735\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.1618\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.1883\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.1751\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.1766\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.1757\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.1759\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.1801\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.1854\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.1869\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.1922\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.1881\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.1817\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.1913\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.1840\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.1964\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.1987\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.1971\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.1860\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.1934\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.2081\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.2014\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.1937\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.2088\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.2051\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.2067\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.1946\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.1977\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.2123\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.2087\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.2023\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.2054\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.2056\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.2055\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.2149\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.2087\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.1979\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.2029\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.2131\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.2133\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.2022\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.2106\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.2061\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.2013\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.2190\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.2133\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.2063\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.2080\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.2107\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.2133\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.2212\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.2139\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.2182\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.2089\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.2130\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.2266\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.2131\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.1926\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.2001\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.2086\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.2143\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.2187\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.2283\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.2212\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.2137\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.2136\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.2241\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.2222\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.2167\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.2097\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.2300\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.2174\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.2109\n"
     ]
    }
   ],
   "source": [
    "# Create 6 layer model.\n",
    "input_dim = train_dataset['x'].shape[1]\n",
    "input = Input(shape=(input_dim, ))\n",
    "encode = Dense(input_dim//3*2, activation='relu',kernel_regularizer=regularizers.l2(0.01))(input)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(input_dim//3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(1, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "encode = BatchNormalization()(encode)\n",
    "\n",
    "decode = Dense(input_dim//3, activation='relu')(encode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim//3*2, activation='relu')(decode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim, activation='sigmoid')(decode)\n",
    "\n",
    "autoencoder = Model(input, decode)\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer='adam',\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Train model.\n",
    "history = autoencoder.fit(train_dataset['x'], train_dataset['x'],\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        shuffle=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_dataset['x_1auto'] = autoencoder.predict(train_dataset['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(random_state = 42, contamination = 0.3)\n",
    "clf.fit(train_dataset['x_1auto'])\n",
    "pred = clf.predict(train_dataset['x_1auto'])\n",
    "\n",
    "p1 = train_dataset['x_1auto'][pred==1]\n",
    "p2 = train_dataset['x_1auto'][pred==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.8333 - accuracy: 0.4178\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.4466\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7567 - accuracy: 0.3922\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.3968\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.3738\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.0560\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.1492\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.1488\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.1415\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.1437\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.1354\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.1381\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.1366\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.1331\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.1401\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.1325\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.1363\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.1421\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.1365\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.1359\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.1346\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.1379\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3180 - accuracy: 0.1360\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.1356\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.1398\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.3057\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.1543\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.6205\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.5790\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.6796\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.6877\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.6508\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.6415\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.6286\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.6489\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.6197\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.6355\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.6347\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2906 - accuracy: 0.6403\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2908 - accuracy: 0.6235\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2913 - accuracy: 0.5847\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2913 - accuracy: 0.5498\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.4727\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8109\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.6042\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.8718\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8966\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.8957\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.8872\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.2866 - accuracy: 0.8987\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2863 - accuracy: 0.8941\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.9031\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.9244\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.9146\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.9129\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2880 - accuracy: 0.9036\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.2868 - accuracy: 0.8915\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8797\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8591\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8694\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2881 - accuracy: 0.8694\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8512\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8535\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8451\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.8597\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8438\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.8524\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2863 - accuracy: 0.8463\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8403\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8505\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8379\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8480\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.8285\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8423\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8670\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8287\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.8605\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8419\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8593\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8561\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2872 - accuracy: 0.8692\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.8715\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8666\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2850 - accuracy: 0.8652\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8492\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8545\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.8794\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8763\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8611\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.8919\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8739\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.8667\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8747\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.9026\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8793\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8964\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8785\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8789\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8986\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.9008\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder model.\n",
    "input_dim = p1.shape[1]\n",
    "input = Input(shape=(input_dim, ))\n",
    "encode = Dense(input_dim//3*2, activation='relu',kernel_regularizer=regularizers.l2(0.01))(input)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(input_dim//3, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "encode = BatchNormalization()(encode)\n",
    "encode = Dense(1, activation='relu',kernel_regularizer=regularizers.l2(0.01))(encode)\n",
    "\n",
    "decode = Dense(input_dim//3, activation='relu')(encode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim//3*2, activation='relu')(decode)\n",
    "decode = BatchNormalization()(decode)\n",
    "decode = Dense(input_dim, activation='sigmoid')(decode)\n",
    "\n",
    "autoencoder = Model(input, decode)\n",
    "\n",
    "autoencoder.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Train model.\n",
    "history = autoencoder.fit(p1, p1,\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        shuffle=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9270868897438049"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "max(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}